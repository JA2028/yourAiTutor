# yourAiTutor
AI Micro-Mentor is a full-stack learning platform that turns student notes or textbook chapters into personalized study materials. Users can upload content, and the system generates flashcards, quizzes, explanations, and adaptive study paths based on performance using AI and vector search.
ğŸš€ Features
Core (MVP)

Upload notes (PDF, pasted text, typed content)

Automatic text cleaning + structuring

AI-generated flashcards & quizzes

Dashboard to review generated items

User authentication (Supabase Auth)

Intermediate

Chunking + embeddings for vector search

Adaptive quizzes based on weak areas

Performance tracking & analytics

Saved AI study sessions and history

Advanced (Planned)

Spaced repetition scheduling

AI-generated weekly study plan

Topic-level knowledge graph

Teacher/Instructor mode for bulk notes

ğŸ¯ Problem This Project Solves

Students often review material inefficiently because they donâ€™t know:

What theyâ€™ve mastered

What they need to practice

How to turn large notes into actionable study tasks

AI Micro-Mentor fixes this by converting raw notes into structured learning content and adapting to the studentâ€™s understanding over time. It acts like a personal tutor â€” automated, always available, and powered by retrieval-augmented AI.

ğŸ§  High-Level Architecture
Frontend (Next.js)
     â†“
Backend API (Node.js or FastAPI)
     â†“
AI Layer (LLM calls + prompt templates)
     â†“
Vector Store (pgvector / Pinecone)
     â†“
Database (Supabase/Postgres)

Flow Summary

User uploads notes

Text is extracted â†’ cleaned â†’ chunked

Embeddings generated â†’ stored in vector DB

User requests flashcards or quiz

Relevant chunks retrieved via similarity search

AI produces output using structured prompts

Results saved to DB and shown in UI

ğŸ› ï¸ Tech Stack
Frontend

Next.js (App Router)

React

TailwindCSS

Zustand or Context for state management

Backend

Node.js + Express or Python + FastAPI

Supabase client SDK

OpenAI API for LLM + embeddings

Database & Storage

Supabase Postgres

pgvector (built-in vector search)

Supabase Storage for file uploads

AI

OpenAI GPT-4.1 / GPT-4.1-mini

Embeddings (text-embedding-3-large or small)

RAG pipeline with chunk retrieval

JSON-structured function calling for quizzes

ğŸ“‚ Project Structure
ai-micro-mentor/
â”‚
â”œâ”€â”€ frontend/              # Next.js application
â”œâ”€â”€ backend/               # Node.js or FastAPI API
â”œâ”€â”€ database/              # Schema + migrations
â”œâ”€â”€ llm/                   # Prompt templates + evaluation
â””â”€â”€ scripts/               # Dev & build helpers


Full directory structure is in the repository for clarity.

âš™ï¸ Setup Instructions
1. Clone the repository
git clone https://github.com/your-username/ai-micro-mentor.git
cd ai-micro-mentor

2. Configure Environment Variables

Create .env files in both /frontend and /backend.

Frontend .env
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000

Backend .env
SUPABASE_URL=
SUPABASE_SERVICE_ROLE_KEY=
OPENAI_API_KEY=
DATABASE_URL=

3. Install Dependencies
Frontend
cd frontend
npm install
npm run dev

Backend (Node.js version)
cd backend
npm install
npm run dev

Backend (FastAPI version)
pip install -r requirements.txt
uvicorn src.app:app --reload

4. Database Setup
Supabase SQL (schema.sql)

Run:

-- Users, notes, chunks, flashcards, quizzes, results
-- Vector embeddings stored in pgvector column


Upload seed data if needed:

supabase db restore seed.sql

ğŸ” API Overview
POST /notes/upload

Uploads raw notes â†’ returns extracted text.

POST /notes/embed

Chunks & embeds text â†’ stores vectors.

POST /generate/flashcards

Retrieves relevant chunks â†’ generates flashcards via LLM.

POST /generate/quiz

Retrieves relevant chunks â†’ returns quiz JSON.

POST /quiz/submit

Saves results + updates performance model.

ğŸ“˜ LLM Pipeline Summary

All quiz and flashcard generation uses:

retrieval â†’ fetch relevant note chunks

formatting â†’ normalize text

prompting â†’ structured messages

function calling â†’ enforce JSON output

Prompts live in /llm/prompts/.

ğŸ“Š Adaptive Learning Logic (Simplified)

Track success rate per concept

Identify weak areas (below threshold)

Query vector DB for similar chunks

Generate targeted questions

Schedule spaced repetition intervals

This forms the â€œAI mentorâ€ behavior.

ğŸ§ª Testing
Frontend
npm run test

Backend
pytest  # if Python
npm run test  # if Node

ğŸ›£ï¸ Roadmap
Phase 1 â€” MVP

 Notes upload + extract

 Flashcard generator

 Basic quizzes

 User login + dashboard

Phase 2 â€” Smart Features

 Embeddings + retrieval

 Adaptive quizzes

 Progress tracking

Phase 3 â€” Advanced

 Spaced repetition

 AI study plan generator

 Knowledge graph UI
